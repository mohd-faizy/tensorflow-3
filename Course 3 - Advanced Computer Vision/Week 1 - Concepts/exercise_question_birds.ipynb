{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "exercise-question-birds.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsjDCIat6_UK"
      },
      "source": [
        "#TensorFlow - Advanced Computer Vision Week 1 Exercise\n",
        "\n",
        "\n",
        "**Question**\n",
        "\n",
        "Build a model that predicts the bounding boxes in [Caltech Birds - 2010](http://www.vision.caltech.edu/visipedia/CUB-200.html) dataset. \n",
        "\n",
        "You are encouraged to use transfer learning for your solution. When you're done training your model, you will save it as a .H5 file.\n",
        "\n",
        "This file will be uploaded to our infrastructure for grading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpiJj8ym0v0-"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoilhmYe1b5t"
      },
      "source": [
        "import os, re, time, json\n",
        "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
        "import numpy as np\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRl07kRr7uny"
      },
      "source": [
        "# If you get a checksum error with the dataset, you'll need this\n",
        "!pip install tfds-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmoFKEd98MP3"
      },
      "source": [
        "#Visualization Utilities\n",
        "\n",
        "These functions are used to draw bounding boxes around the birds in images.\n",
        "\n",
        "DO NOT CHANGE THIS CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBjj1Fg-i_lc",
        "cellView": "both"
      },
      "source": [
        "#@title Plot Utilities for Bounding Boxes [RUN ME]\n",
        "\n",
        "im_width = 224\n",
        "im_height = 224\n",
        "\n",
        "def draw_bounding_boxes_on_image_array(image,\n",
        "                                       boxes,\n",
        "                                       color=[],\n",
        "                                       thickness=5):\n",
        "  \"\"\"Draws bounding boxes on image (numpy array).\n",
        "  Args:\n",
        "    image: a numpy array object.\n",
        "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
        "           The coordinates are in normalized format between [0, 1].\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "    display_str_list_list: a list of strings for each bounding box.\n",
        "  Raises:\n",
        "    ValueError: if boxes is not a [N, 4] array\n",
        "  \"\"\"\n",
        "\n",
        "  draw_bounding_boxes_on_image(image, boxes, color, thickness)\n",
        "  \n",
        "  return image\n",
        "  \n",
        "\n",
        "def draw_bounding_boxes_on_image(image,\n",
        "                                 boxes,\n",
        "                                 color=[],\n",
        "                                 thickness=5):\n",
        "  \"\"\"Draws bounding boxes on image.\n",
        "  Args:\n",
        "    image: a PIL.Image object.\n",
        "    boxes: a 2 dimensional numpy array of [N, 4]: (ymin, xmin, ymax, xmax).\n",
        "           The coordinates are in normalized format between [0, 1].\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "                           \n",
        "  Raises:\n",
        "    ValueError: if boxes is not a [N, 4] array\n",
        "  \"\"\"\n",
        "  boxes_shape = boxes.shape\n",
        "  if not boxes_shape:\n",
        "    return\n",
        "  if len(boxes_shape) != 2 or boxes_shape[1] != 4:\n",
        "    raise ValueError('Input must be of size [N, 4]')\n",
        "  for i in range(boxes_shape[0]):\n",
        "    draw_bounding_box_on_image(image, boxes[i, 1], boxes[i, 0], boxes[i, 3],\n",
        "                               boxes[i, 2], color[i], thickness)\n",
        "        \n",
        "def draw_bounding_box_on_image(image,\n",
        "                               ymin,\n",
        "                               xmin,\n",
        "                               ymax,\n",
        "                               xmax,\n",
        "                               color=(255, 0, 0),\n",
        "                               thickness=5):\n",
        "  \"\"\"Adds a bounding box to an image.\n",
        "  Bounding box coordinates can be specified in either absolute (pixel) or\n",
        "  normalized coordinates by setting the use_normalized_coordinates argument.\n",
        "  Args:\n",
        "    image: a PIL.Image object.\n",
        "    ymin: ymin of bounding box.\n",
        "    xmin: xmin of bounding box.\n",
        "    ymax: ymax of bounding box.\n",
        "    xmax: xmax of bounding box.\n",
        "    color: color to draw bounding box. Default is red.\n",
        "    thickness: line thickness. Default value is 4.\n",
        "  \"\"\"\n",
        "  im_width = image.shape[1]\n",
        "  im_height = image.shape[0]\n",
        "  cv2.rectangle(image, (int(xmin), int(ymin)), (int(xmax), int(ymax)), color, thickness)\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USx9tRBF8hWy"
      },
      "source": [
        "These utilities are used to visualize the data and predictions.\n",
        "\n",
        "DO NOT CHANGE THIS CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "qhdz68Xm3Z4Z"
      },
      "source": [
        "#@title Visualization Utilities [RUN ME]\n",
        "\"\"\"\n",
        "This cell contains helper functions used for visualization\n",
        "and downloads only. You can skip reading it. There is very\n",
        "little useful Keras/Tensorflow code here.\n",
        "\"\"\"\n",
        "\n",
        "# Matplotlib config\n",
        "plt.rc('image', cmap='gray')\n",
        "plt.rc('grid', linewidth=0)\n",
        "plt.rc('xtick', top=False, bottom=False, labelsize='large')\n",
        "plt.rc('ytick', left=False, right=False, labelsize='large')\n",
        "plt.rc('axes', facecolor='F8F8F8', titlesize=\"large\", edgecolor='white')\n",
        "plt.rc('text', color='a8151a')\n",
        "plt.rc('figure', facecolor='F0F0F0')# Matplotlib fonts\n",
        "MATPLOTLIB_FONT_DIR = os.path.join(os.path.dirname(plt.__file__), \"mpl-data/fonts/ttf\")\n",
        "\n",
        "\n",
        "\n",
        "# utility to display a row of digits with their predictions\n",
        "def display_digits_with_boxes(images, pred_bboxes, bboxes, iou, title, bboxes_normalized=False):\n",
        "\n",
        "  n = len(images)\n",
        "\n",
        "  fig = plt.figure(figsize=(20, 4))\n",
        "  plt.title(title)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])\n",
        "  \n",
        "  for i in range(n):\n",
        "    ax = fig.add_subplot(1, 10, i+1)\n",
        "    bboxes_to_plot = []\n",
        "    if (len(pred_bboxes) > i):\n",
        "      bbox = pred_bboxes[i]\n",
        "      bbox = [bbox[0] * images[i].shape[1], bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0]]\n",
        "      bboxes_to_plot.append(bbox)\n",
        "    \n",
        "    if (len(bboxes) > i):\n",
        "      bbox = bboxes[i]\n",
        "      if bboxes_normalized == True:\n",
        "        bbox = [bbox[0] * images[i].shape[1],bbox[1] * images[i].shape[0], bbox[2] * images[i].shape[1], bbox[3] * images[i].shape[0] ]\n",
        "      bboxes_to_plot.append(bbox)\n",
        "\n",
        "    img_to_draw = draw_bounding_boxes_on_image_array(image=images[i], boxes=np.asarray(bboxes_to_plot), color=[(255,0,0), (0, 255, 0)])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    \n",
        "    plt.imshow(img_to_draw)\n",
        "\n",
        "    if len(iou) > i :\n",
        "      color = \"black\"\n",
        "      if (iou[i][0] < iou_threshold):\n",
        "        color = \"red\"\n",
        "      ax.text(0.2, -0.3, \"iou: %s\" %(iou[i][0]), color=color, transform=ax.transAxes)\n",
        "\n",
        "\n",
        "# utility to display training and validation curves\n",
        "def plot_metrics(metric_name, title, ylim=5):\n",
        "  plt.title(title)\n",
        "  plt.ylim(0,ylim)\n",
        "  plt.plot(history.history[metric_name],color='blue',label=metric_name)\n",
        "  plt.plot(history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCpkS9C_H7Tl"
      },
      "source": [
        "BATCH_SIZE = # YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVkc7nzg-WUy"
      },
      "source": [
        "##Loading and Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Xv_8MbApX23"
      },
      "source": [
        "###Utility and Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE8dgyPC1_6m"
      },
      "source": [
        "# DO NOT CHANGE THIS CODE\n",
        "'''\n",
        "Resizes image to (224, 224), normalizes image and translates and normalizes bounding boxes.\n",
        "'''\n",
        "def read_image_tfds(image, bbox):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    shape = tf.shape(image)\n",
        "\n",
        "    factor_x = tf.cast(shape[1], tf.float32)\n",
        "    factor_y = tf.cast(shape[0], tf.float32)\n",
        "\n",
        "    image = tf.image.resize(image, (224, 224,))\n",
        "\n",
        "    image = image/127.5\n",
        "    image -= 1\n",
        "\n",
        "    return image, [bbox[0] / factor_x , bbox[1] / factor_y, bbox[2] / factor_x , bbox[3] / factor_y]\n",
        "\n",
        "'''\n",
        "Helper function to read resized images, bounding boxes and their original shapes.\n",
        "Resizes image to (224, 224), normalizes image and translates and normalizes bounding boxes.\n",
        "'''\n",
        "def read_image_with_shape(image, bbox):\n",
        "    original_image = image\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    shape = tf.shape(image)\n",
        "    \n",
        "    factor_x = tf.cast(shape[1], tf.float32)\n",
        "    factor_y = tf.cast(shape[0], tf.float32)\n",
        "\n",
        "    image = tf.image.resize(image, (224, 224,))\n",
        "\n",
        "    image = image/127.5\n",
        "    image -= 1\n",
        "\n",
        "    return original_image, image, [bbox[0] / factor_x , bbox[1] / factor_y, bbox[2] / factor_x , bbox[3] / factor_y]\n",
        "\n",
        "'''\n",
        "Reads image and denormalized bounding boxes\n",
        "'''\n",
        "def read_image_tfds_with_original_bbox(data):\n",
        "    image = data[\"image\"]\n",
        "    bbox = data[\"bbox\"]\n",
        "\n",
        "    shape = tf.shape(image)\n",
        "\n",
        "    return image, [bbox[1] * tf.cast(shape[1], tf.float32) , bbox[0] * tf.cast(shape[0], tf.float32), bbox[3] * tf.cast(shape[1], tf.float32), bbox[2] * tf.cast(shape[0], tf.float32)] #[bbox[0] * factor_x , (bbox[1] * factor_y), (bbox[2] * factor_x), (bbox[3] * factor_y)]\n",
        "\n",
        "  \n",
        "'''\n",
        "Convert dataset to numpy arrays of images and boxes.\n",
        "'''\n",
        "def dataset_to_numpy_util(dataset, batch_size=0, N=0):\n",
        "\n",
        "  # eager execution: loop through datasets normally\n",
        "  take_dataset = dataset.shuffle(1024)\n",
        "\n",
        "  if batch_size > 0:\n",
        "    take_dataset = take_dataset.batch(batch_size)\n",
        "  \n",
        "  if N > 0:\n",
        "    take_dataset = take_dataset.take(N)\n",
        "  \n",
        "  if tf.executing_eagerly():\n",
        "    ds_images, ds_bboxes = [], []\n",
        "    for images, bboxes in take_dataset:\n",
        "      ds_images.append(images.numpy())\n",
        "      ds_bboxes.append(bboxes.numpy())\n",
        "        \n",
        "  return (np.array(ds_images), np.array(ds_bboxes))\n",
        "\n",
        "'''\n",
        "Convert dataset to numpy arrays of original images, resized and normalized images and bounding boxes.\n",
        "This is used for plotting the original images with true and predicted bounding boxes.\n",
        "'''\n",
        "def dataset_to_numpy_with_original_bboxes_util(dataset, batch_size=0, N=0):\n",
        "\n",
        "  normalized_dataset = dataset.map(read_image_with_shape)\n",
        "  if batch_size > 0:\n",
        "    normalized_dataset = normalized_dataset.batch(batch_size)\n",
        "  \n",
        "  if N > 0:\n",
        "    normalized_dataset = normalized_dataset.take(N)\n",
        "\n",
        "  \n",
        "  if tf.executing_eagerly():\n",
        "    ds_original_images, ds_images, ds_bboxes = [], [], []\n",
        "    for original_images, images, bboxes in normalized_dataset:\n",
        "      ds_images.append(images.numpy())\n",
        "      ds_bboxes.append(bboxes.numpy())\n",
        "      ds_original_images.append(original_images.numpy())\n",
        "\n",
        "  return np.array(ds_original_images), np.array(ds_images), np.array(ds_bboxes)#, np.array(ds_normalized_images), np.array(ds_normalized_bboxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpqbjqwgpfTU"
      },
      "source": [
        "###Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V8F31UMJ75r"
      },
      "source": [
        "# DO NOT CHANGE THIS CODE\n",
        "'''\n",
        "Loads and maps the training split of the dataset. It used map function to reverse the normalization done on the bounding boxes in the dataset.\n",
        "This will generate the dataset prepared for visualization\n",
        "''' \n",
        "def get_visualization_training_dataset():      \n",
        "    dataset, info = tfds.load(\"caltech_birds2010\", split=\"train\", with_info=True)\n",
        "    print(info)\n",
        "    visualization_training_dataset = dataset.map(read_image_tfds_with_original_bbox, num_parallel_calls=16)\n",
        "    return visualization_training_dataset\n",
        "    \n",
        "\n",
        "'''\n",
        "Loads and maps the validation split of the dataset. It used map function to reverse the normalization done on the bounding boxes in the dataset.\n",
        "This will generate the dataset prepared for visualization\n",
        "''' \n",
        "def get_visualization_validation_dataset():\n",
        "    dataset = tfds.load(\"caltech_birds2010\", split=\"test\", try_gcs=True)\n",
        "    visualization_validation_dataset = dataset.map(read_image_tfds_with_original_bbox, num_parallel_calls=16)\n",
        "    return visualization_validation_dataset\n",
        "\n",
        "'''\n",
        "Loads and maps the training split of the dataset using the map function for resizing, image normalization and bounding box translation.\n",
        "'''  \n",
        "def get_training_dataset(dataset):\n",
        "  dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "  dataset = dataset.shuffle(512, reshuffle_each_iteration=True)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.prefetch(-1) \n",
        "  return dataset\n",
        "\n",
        "'''\n",
        "Loads and maps the validation split of the dataset using the map function for resizing, image normalization and bounding box translation.\n",
        "'''  \n",
        "def get_validation_dataset(dataset):\n",
        "  dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset\n",
        "  \n",
        "\n",
        "# instantiate the datasets\n",
        "visualization_training_dataset = get_visualization_training_dataset()\n",
        "visualization_validation_dataset = get_visualization_validation_dataset()\n",
        "\n",
        "training_dataset = get_training_dataset(visualization_training_dataset)\n",
        "validation_dataset = get_validation_dataset(visualization_validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fXo6GuvL3EB"
      },
      "source": [
        "### Visualize Data\n",
        "We take a random sample of images from training and validation set and visualize them by plotting the corresponding bounding boxes. We use the visualization datasets we prepared earlier for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZ4tjPKvL2eh"
      },
      "source": [
        "# DO NOT CHANGE THIS CODE\n",
        "(visualization_training_images, visualization_training_bboxes) = dataset_to_numpy_util(visualization_training_dataset, N=10)\n",
        "display_digits_with_boxes(np.array(visualization_training_images), np.array([]), np.array(visualization_training_bboxes), np.array([]), \"training images and their bboxes\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLbcbzGKGIDP"
      },
      "source": [
        "# DO NOT CHANGE THIS CODE\n",
        "(visualization_validation_images, visualization_validation_bboxes)= dataset_to_numpy_util(visualization_validation_dataset, N=10)\n",
        "display_digits_with_boxes(np.array(visualization_validation_images), np.array([]), np.array(visualization_validation_bboxes), np.array([]), \"validation images and their bboxes\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8nHWWkS_eeZ"
      },
      "source": [
        "##Define the Network\n",
        "\n",
        "Bounding box prediction is treated as a regression problem.\n",
        "\n",
        "Here is where you write YOUR code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56y8UNFQIVwj"
      },
      "source": [
        "\n",
        "def feature_extractor(inputs):\n",
        "    resnet_model = # YOUR CODE HERE\n",
        "    return feature_extractor\n",
        "\n",
        "\n",
        "'''\n",
        "Defines final dense layers.\n",
        "'''\n",
        "def dense_layers(inputs):\n",
        "    x = # YOUR CODE HERE -- maybe multiple layers\n",
        "    return x\n",
        "\n",
        "'''\n",
        "This function defines the regression output for bounding box prediction. Note that we have four units in output layer corresponding to (xmin, ymin, xmax, ymax).\n",
        "'''\n",
        "def bounding_box_regression(inputs):\n",
        "    bounding_box_regression_output = # YOUR CODE HERE\n",
        "    return bounding_box_regression_output\n",
        "\n",
        "'''\n",
        "Connects the feature extraction, fully connected layers and regression layer to build the final model.\n",
        "'''\n",
        "def final_model(inputs):\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return model\n",
        "  \n",
        "\n",
        "'''\n",
        "Defines the final model and compiles it. We opt to use Stochastic Gradient Descent as the optimizer with momentum of 0.9 and mse as the loss function.\n",
        "'''\n",
        "def define_and_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(224, 224, 3,))\n",
        "  model = final_model(inputs)\n",
        "  \n",
        "  model.compile(# YOUR CODE HERE)\n",
        "  return model\n",
        "\n",
        "    \n",
        "model = define_and_compile_model()\n",
        "\n",
        "# print model layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuhDh8ao8VyB"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTwH_P-ZJ_xx"
      },
      "source": [
        "EPOCHS = 80\n",
        "steps_per_epoch = 3000//BATCH_SIZE  # 3000 items in this dataset\n",
        "validation_steps = 3033//BATCH_SIZE\n",
        "\n",
        "history = model.fit(# YOUR CODE HERE)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aBzmycIsO8w"
      },
      "source": [
        "##Validate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWbkUql5sAok"
      },
      "source": [
        "loss = model.evaluate(validation_dataset, steps=validation_steps)\n",
        "print(\"Loss: \", loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cvv-GgvE3V4"
      },
      "source": [
        "# You should save your model -- it might be quite large\n",
        "# Example we used is 34Mb\n",
        "# Be sure to download it to your computer after saving\n",
        "model.save(\"birds.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7E81sgUsUC4"
      },
      "source": [
        "###Plot Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz-b8TxU6EDj"
      },
      "source": [
        "plot_metrics(\"loss\", \"Bounding Box Loss\", ylim=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G7KFVX9sXJt"
      },
      "source": [
        "###Intersection Over Union"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFqJxt3_VrCm"
      },
      "source": [
        "'''\n",
        "Calulcates and returns list of iou scores for all images in the test set\n",
        "'''\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def intersection_over_union(pred_box, true_box):\n",
        "\n",
        "    xmin_pred, ymin_pred, xmax_pred, ymax_pred =  np.split(pred_box, 4, axis = 1)\n",
        "    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n",
        "\n",
        "    #Calculate coordinates of overlap area between boxes\n",
        "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
        "    ymin_overlap = np.maximum(xmin_pred, xmin_true)\n",
        "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
        "\n",
        "    #Calculates area of true and predicted boxes\n",
        "    pred_box_area = (xmax_pred - xmin_pred + 1) * (ymax_pred - ymin_pred + 1)\n",
        "    true_box_area = (xmax_true - xmin_true + 1) * (ymax_true - ymin_true + 1)\n",
        "\n",
        "    #Calculates overlap area and union area.\n",
        "    overlap_area = np.maximum((xmax_overlap - xmin_overlap) + 1,0)  * np.maximum((ymax_overlap - ymin_overlap) + 1, 0)\n",
        "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
        "\n",
        "    #Updates iou score\n",
        "    iou = overlap_area / union_area\n",
        "\n",
        "    return iou\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpiXQ0vJFWKF"
      },
      "source": [
        "#Makes predictions\n",
        "#DO NOT CHANGE THIS CODE\n",
        "original_images, normalized_images, normalized_bboxes = dataset_to_numpy_with_original_bboxes_util(visualization_validation_dataset, N=500)\n",
        "predicted_bboxes = model.predict(normalized_images, batch_size=32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKLYgYV7wfM7"
      },
      "source": [
        "#Calculates IOU and reports true positives and false positives based on IOU threshold\n",
        "# DO NOT CHANGE THIS CODE. \n",
        "# YOU CAN USE THIS TO CHECK GRADING\n",
        "# WE EXPECT YOUR MODEL TO HAVE OVER 50% OF THE PREDICTIONS OVER 70% IOU\n",
        "iou = intersection_over_union(predicted_bboxes, normalized_bboxes)\n",
        "iou_threshold = 0.7\n",
        "\n",
        "print(\"Number of predictions where iou > threshold(%s): %s\" % (iou_threshold, (iou >= iou_threshold).sum()))\n",
        "print(\"Number of predictions where iou < threshold(%s): %s\" % (iou_threshold, (iou < iou_threshold).sum()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jFVovcUUVs1"
      },
      "source": [
        "### Visualize predictions\n",
        "Plot predicted and ground truth bounding boxes for a random set of images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR9Bb4uCwTyw"
      },
      "source": [
        "n = 10\n",
        "indexes = np.random.choice(len(predicted_bboxes), size=n)\n",
        "\n",
        "iou_to_draw = iou[indexes]\n",
        "norm_to_draw = original_images[indexes]\n",
        "display_digits_with_boxes(original_images[indexes], predicted_bboxes[indexes], normalized_bboxes[indexes], iou[indexes], \"True and Predicted values\", bboxes_normalized=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
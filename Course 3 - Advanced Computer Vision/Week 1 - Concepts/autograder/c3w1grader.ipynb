{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AoilhmYe1b5t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os, re, time, json\n",
    "import PIL.Image, PIL.ImageFont, PIL.ImageDraw\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRl07kRr7uny"
   },
   "outputs": [],
   "source": [
    "# If you get a checksum error with the dataset, you'll need this\n",
    "!pip install tfds-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JQ7N-xX_IGWK"
   },
   "outputs": [],
   "source": [
    "# HERE IS WHERE YOU LOAD THE STUDENTS MODEL\n",
    "model = tf.keras.models.load_model(\"birds.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZE8dgyPC1_6m"
   },
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "'''\n",
    "Resizes image to (224, 224), normalizes image and translates and normalizes bounding boxes.\n",
    "'''\n",
    "def read_image_tfds(image, bbox):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    factor_x = tf.cast(shape[1], tf.float32)\n",
    "    factor_y = tf.cast(shape[0], tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, (224, 224,))\n",
    "\n",
    "    image = image/127.5\n",
    "    image -= 1\n",
    "\n",
    "    return image, [bbox[0] / factor_x , bbox[1] / factor_y, bbox[2] / factor_x , bbox[3] / factor_y]\n",
    "\n",
    "'''\n",
    "Helper function to read resized images, bounding boxes and their original shapes.\n",
    "Resizes image to (224, 224), normalizes image and translates and normalizes bounding boxes.\n",
    "'''\n",
    "def read_image_with_shape(image, bbox):\n",
    "    original_image = image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    shape = tf.shape(image)\n",
    "    \n",
    "    factor_x = tf.cast(shape[1], tf.float32)\n",
    "    factor_y = tf.cast(shape[0], tf.float32)\n",
    "\n",
    "    image = tf.image.resize(image, (224, 224,))\n",
    "\n",
    "    image = image/127.5\n",
    "    image -= 1\n",
    "\n",
    "    return original_image, image, [bbox[0] / factor_x , bbox[1] / factor_y, bbox[2] / factor_x , bbox[3] / factor_y]\n",
    "\n",
    "'''\n",
    "Reads image and denormalized bounding boxes\n",
    "'''\n",
    "def read_image_tfds_with_original_bbox(data):\n",
    "    image = data[\"image\"]\n",
    "    bbox = data[\"bbox\"]\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "\n",
    "    return image, [bbox[1] * tf.cast(shape[1], tf.float32) , bbox[0] * tf.cast(shape[0], tf.float32), bbox[3] * tf.cast(shape[1], tf.float32), bbox[2] * tf.cast(shape[0], tf.float32)] #[bbox[0] * factor_x , (bbox[1] * factor_y), (bbox[2] * factor_x), (bbox[3] * factor_y)]\n",
    "\n",
    "  \n",
    "'''\n",
    "Convert dataset to numpy arrays of images and boxes.\n",
    "'''\n",
    "def dataset_to_numpy_util(dataset, batch_size=0, N=0):\n",
    "\n",
    "  # eager execution: loop through datasets normally\n",
    "  take_dataset = dataset.shuffle(1024)\n",
    "\n",
    "  if batch_size > 0:\n",
    "    take_dataset = take_dataset.batch(batch_size)\n",
    "  \n",
    "  if N > 0:\n",
    "    take_dataset = take_dataset.take(N)\n",
    "  \n",
    "  if tf.executing_eagerly():\n",
    "    ds_images, ds_bboxes = [], []\n",
    "    for images, bboxes in take_dataset:\n",
    "      ds_images.append(images.numpy())\n",
    "      ds_bboxes.append(bboxes.numpy())\n",
    "        \n",
    "  return (np.array(ds_images), np.array(ds_bboxes))\n",
    "\n",
    "'''\n",
    "Convert dataset to numpy arrays of original images, resized and normalized images and bounding boxes.\n",
    "This is used for plotting the original images with true and predicted bounding boxes.\n",
    "'''\n",
    "def dataset_to_numpy_with_original_bboxes_util(dataset, batch_size=0, N=0):\n",
    "\n",
    "  normalized_dataset = dataset.map(read_image_with_shape)\n",
    "  if batch_size > 0:\n",
    "    normalized_dataset = normalized_dataset.batch(batch_size)\n",
    "  \n",
    "  if N > 0:\n",
    "    normalized_dataset = normalized_dataset.take(N)\n",
    "\n",
    "  \n",
    "  if tf.executing_eagerly():\n",
    "    ds_original_images, ds_images, ds_bboxes = [], [], []\n",
    "    for original_images, images, bboxes in normalized_dataset:\n",
    "      ds_images.append(images.numpy())\n",
    "      ds_bboxes.append(bboxes.numpy())\n",
    "      ds_original_images.append(original_images.numpy())\n",
    "\n",
    "  return np.array(ds_original_images), np.array(ds_images), np.array(ds_bboxes)#, np.array(ds_normalized_images), np.array(ds_normalized_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5V8F31UMJ75r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='caltech_birds2010',\n",
      "    version=0.1.1,\n",
      "    description='Caltech-UCSD Birds 200 (CUB-200) is an image dataset with photos \n",
      "of 200 bird species (mostly North American). The total number of \n",
      "categories of birds is 200 and there are 6033 images in the 2010 \n",
      "dataset and 11,788 images in the 2011 dataset.\n",
      "Annotations include bounding boxes, segmentation labels.',\n",
      "    homepage='http://www.vision.caltech.edu/visipedia/CUB-200.html',\n",
      "    features=FeaturesDict({\n",
      "        'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
      "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
      "        'image/filename': Text(shape=(), dtype=tf.string),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=200),\n",
      "        'label_name': Text(shape=(), dtype=tf.string),\n",
      "        'segmentation_mask': Image(shape=(None, None, 1), dtype=tf.uint8),\n",
      "    }),\n",
      "    total_num_examples=6033,\n",
      "    splits={\n",
      "        'test': 3033,\n",
      "        'train': 3000,\n",
      "    },\n",
      "    supervised_keys=('image', 'label'),\n",
      "    citation=\"\"\"@techreport{WelinderEtal2010,\n",
      "    Author = {P. Welinder and S. Branson and T. Mita and C. Wah and F. Schroff and S. Belongie and P. Perona},\n",
      "    Institution = {California Institute of Technology},\n",
      "    Number = {CNS-TR-2010-001},\n",
      "    Title = {{Caltech-UCSD Birds 200}},\n",
      "    Year = {2010}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DO NOT CHANGE THIS CODE\n",
    "'''\n",
    "Loads and maps the training split of the dataset. It used map function to reverse the normalization done on the bounding boxes in the dataset.\n",
    "This will generate the dataset prepared for visualization\n",
    "''' \n",
    "def get_visualization_training_dataset():      \n",
    "    dataset, info = tfds.load(\"caltech_birds2010\", split=\"train\", with_info=True, data_dir=\"./data\", download=False)\n",
    "    print(info)\n",
    "    visualization_training_dataset = dataset.map(read_image_tfds_with_original_bbox, num_parallel_calls=16)\n",
    "    return visualization_training_dataset\n",
    "    \n",
    "\n",
    "'''\n",
    "Loads and maps the validation split of the dataset. It used map function to reverse the normalization done on the bounding boxes in the dataset.\n",
    "This will generate the dataset prepared for visualization\n",
    "''' \n",
    "def get_visualization_validation_dataset():\n",
    "    dataset = tfds.load(\"caltech_birds2010\", split=\"test\", try_gcs=True, data_dir=\"./data\", download=False)\n",
    "    visualization_validation_dataset = dataset.map(read_image_tfds_with_original_bbox, num_parallel_calls=16)\n",
    "    return visualization_validation_dataset\n",
    "\n",
    "'''\n",
    "Loads and maps the training split of the dataset using the map function for resizing, image normalization and bounding box translation.\n",
    "'''  \n",
    "def get_training_dataset(dataset):\n",
    "  dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
    "  dataset = dataset.shuffle(512, reshuffle_each_iteration=True)\n",
    "  dataset = dataset.repeat()\n",
    "  dataset = dataset.batch(BATCH_SIZE)\n",
    "  dataset = dataset.prefetch(-1) \n",
    "  return dataset\n",
    "\n",
    "'''\n",
    "Loads and maps the validation split of the dataset using the map function for resizing, image normalization and bounding box translation.\n",
    "'''  \n",
    "def get_validation_dataset(dataset):\n",
    "  dataset = dataset.map(read_image_tfds, num_parallel_calls=16)\n",
    "  dataset = dataset.batch(BATCH_SIZE)\n",
    "  dataset = dataset.repeat()\n",
    "  return dataset\n",
    "  \n",
    "\n",
    "# instantiate the datasets\n",
    "visualization_training_dataset = get_visualization_training_dataset()\n",
    "visualization_validation_dataset = get_visualization_validation_dataset()\n",
    "\n",
    "training_dataset = get_training_dataset(visualization_training_dataset)\n",
    "validation_dataset = get_validation_dataset(visualization_validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YFqJxt3_VrCm"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Calulcates and returns list of iou scores for all images in the test set\n",
    "'''\n",
    "# DO NOT CHANGE THIS CODE\n",
    "def intersection_over_union(pred_box, true_box):\n",
    "\n",
    "    xmin_pred, ymin_pred, xmax_pred, ymax_pred =  np.split(pred_box, 4, axis = 1)\n",
    "    xmin_true, ymin_true, xmax_true, ymax_true = np.split(true_box, 4, axis = 1)\n",
    "\n",
    "    #Calculate coordinates of overlap area between boxes\n",
    "    xmin_overlap = np.maximum(xmin_pred, xmin_true)\n",
    "    xmax_overlap = np.minimum(xmax_pred, xmax_true)\n",
    "    ymin_overlap = np.maximum(xmin_pred, xmin_true)\n",
    "    ymax_overlap = np.minimum(ymax_pred, ymax_true)\n",
    "\n",
    "    #Calculates area of true and predicted boxes\n",
    "    pred_box_area = (xmax_pred - xmin_pred + 1) * (ymax_pred - ymin_pred + 1)\n",
    "    true_box_area = (xmax_true - xmin_true + 1) * (ymax_true - ymin_true + 1)\n",
    "\n",
    "    #Calculates overlap area and union area.\n",
    "    overlap_area = np.maximum((xmax_overlap - xmin_overlap) + 1,0)  * np.maximum((ymax_overlap - ymin_overlap) + 1, 0)\n",
    "    union_area = (pred_box_area + true_box_area) - overlap_area\n",
    "\n",
    "    #Updates iou score\n",
    "    iou = overlap_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ihYawWBGJBXS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions where iou > threshold(0.7): 329\n",
      "Number of predictions where iou < threshold(0.7): 171\n",
      "65.8\n",
      "You Passed\n"
     ]
    }
   ],
   "source": [
    "original_images, normalized_images, normalized_bboxes = dataset_to_numpy_with_original_bboxes_util(visualization_validation_dataset, N=500)\n",
    "predicted_bboxes = model.predict(normalized_images, batch_size=32)\n",
    "iou = intersection_over_union(predicted_bboxes, normalized_bboxes)\n",
    "iou_threshold = 0.7\n",
    "\n",
    "beating_threshold = (iou >= iou_threshold).sum()\n",
    "under_threshold = (iou < iou_threshold).sum()\n",
    "print(\"Number of predictions where iou > threshold(%s): %s\" % (iou_threshold, (iou >= iou_threshold).sum()))\n",
    "print(\"Number of predictions where iou < threshold(%s): %s\" % (iou_threshold, (iou < iou_threshold).sum()))\n",
    "\n",
    "grade = beating_threshold * 100 / (beating_threshold + under_threshold)\n",
    "print(grade)\n",
    "PASSING_GRADE = 50\n",
    "if(grade>PASSING_GRADE):\n",
    "  print(\"You Passed\")\n",
    "else:\n",
    "  print(\"You Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "c3w1grader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('trax_py37': conda)",
   "language": "python",
   "name": "python37764bittraxpy37conda5b58c97b4d464a08ba487b857216d7f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

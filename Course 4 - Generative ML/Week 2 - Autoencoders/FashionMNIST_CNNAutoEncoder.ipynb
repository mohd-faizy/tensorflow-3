{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNIST-CNNAutoEncoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXwoz-KHtWO"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9F7YsCNIKSA"
      },
      "source": [
        "# Load the data from TFDS into Training and Test Datasets\n",
        "def map_image(image, label):\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "\n",
        "  return image, image\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "SHUFFLE_BUFFER_SIZE = 1024\n",
        "train_steps = 60000 // BATCH_SIZE\n",
        "valid_steps = 60000 // BATCH_SIZE\n",
        "\n",
        "train_dataset = tfds.load('fashion_mnist', as_supervised=True, split=\"train\")\n",
        "train_dataset = train_dataset.map(map_image)\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "test_dataset = tfds.load('fashion_mnist', as_supervised=True, split=\"test\")\n",
        "test_dataset = test_dataset.map(map_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxh8h-UMk2iL"
      },
      "source": [
        "def encoder(inputs):\n",
        "  conv_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "  max_pool_1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_1)\n",
        "\n",
        "  conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(max_pool_1)\n",
        "  max_pool_2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n",
        "\n",
        "  return max_pool_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRWmLA3VliDr"
      },
      "source": [
        "def bottle_neck(inputs):\n",
        "  bottle_neck = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "  encoder_visualization = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(bottle_neck)\n",
        "\n",
        "  return bottle_neck, encoder_visualization\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZgLt5uAmArk"
      },
      "source": [
        "def decoder(inputs):\n",
        "  conv_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same')(inputs)\n",
        "  up_sample_1 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_1)\n",
        "\n",
        "  conv_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(up_sample_1)\n",
        "  up_sample_2 = tf.keras.layers.UpSampling2D(size=(2,2))(conv_2)\n",
        "\n",
        "  conv_3 = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3), activation='sigmoid', padding='same')(up_sample_2)\n",
        "\n",
        "  return conv_3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQKwO64iiOYl"
      },
      "source": [
        "def convolutional_auto_encoder():\n",
        "  inputs = tf.keras.layers.Input(shape=(28, 28, 1,))\n",
        "  encoder_output = encoder(inputs)\n",
        "  bottleneck_output, encoder_visualization = bottle_neck(encoder_output)\n",
        "  decoder_output = decoder(bottleneck_output)\n",
        "  \n",
        "  model = tf.keras.Model(inputs =inputs, outputs=decoder_output)\n",
        "  encoder_model = tf.keras.Model(inputs=inputs, outputs=encoder_visualization)\n",
        "  return model, encoder_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MmS7r0tkuIf"
      },
      "source": [
        "convolutional_model, convolutional_encoder_model = convolutional_auto_encoder()\n",
        "convolutional_model.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK0RGq5Lt5h_"
      },
      "source": [
        "convolutional_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Umj_xaiHL_"
      },
      "source": [
        "conv_model_history = convolutional_model.fit(train_dataset, steps_per_epoch=train_steps, validation_data=test_dataset, validation_steps=valid_steps, epochs=40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A35RlIqKIsQv"
      },
      "source": [
        "# Helper functions for plotting the encoded and decoded values\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def display_one_row(disp_images, offset, shape=(28, 28)):\n",
        "  for idx, noisy_image in enumerate(disp_images):\n",
        "    plt.subplot(3, 10, offset + idx + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    noisy_image = np.reshape(noisy_image, shape)\n",
        "    plt.imshow(noisy_image, cmap='gray')\n",
        "\n",
        "\n",
        "def display_results(disp_input_images, disp_predicted, disp_encoded, enc_shape=(8,4)):\n",
        "  \n",
        "  plt.figure(figsize=(15, 5))\n",
        "  display_one_row(disp_input_images, 0, shape=(28,28,))\n",
        "  display_one_row(disp_encoded, 10, shape=enc_shape)\n",
        "  display_one_row(disp_predicted, 20, shape=(28,28,))\n",
        "\n",
        "test_dataset = test_dataset.take(1)\n",
        "output_samples = []\n",
        "for input_image, image in tfds.as_numpy(test_dataset):\n",
        "      output_samples = input_image\n",
        "\n",
        "idxs = np.random.choice(128, size=10)\n",
        "idxs = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "\n",
        "conv_output_samples = np.array(output_samples[idxs])\n",
        "conv_output_samples = np.reshape(conv_output_samples, (10, 28, 28, 1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtQyQRxRN_hH"
      },
      "source": [
        "# Get a prediction for some values in the dataset\n",
        "predicted = convolutional_model.predict(conv_output_samples)\n",
        "\n",
        "# Get the encoded values \n",
        "encoded = convolutional_encoder_model.predict(conv_output_samples)\n",
        "\n",
        "# Display the samples, encodings and decoded values!\n",
        "display_results(conv_output_samples, predicted, encoded, enc_shape=(7,7))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
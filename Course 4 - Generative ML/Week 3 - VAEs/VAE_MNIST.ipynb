{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE-MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "17DD2aRgudaO"
      },
      "source": [
        "# All required imports here\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBoDTLNXuFqT"
      },
      "source": [
        "# Define constants to be used in this notebook\n",
        "BATCH_SIZE=128\n",
        "LATENT_DIM=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXgPMPNbteYU"
      },
      "source": [
        "# There are 2 mapping functions that we'll use on the data\n",
        "# The first, map_image, simply normalizes and creates a \n",
        "# tensor from the image, returning only the image. \n",
        "# This will be used for the unsupervised learning in the autoencoder\n",
        "def map_image(image, label):\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image, shape=(28, 28, 1,))\n",
        "  return image\n",
        "\n",
        "# The second, map_image_with_labels does the same\n",
        "# but also returns labels with the image\n",
        "# Which we will use in the dataset that's used to \n",
        "# validate the output predictions. \n",
        "def map_image_with_labels(image, label):\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image, shape=(28, 28, 1,))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sxr6w0ttqmh"
      },
      "source": [
        "# The get dataset function loads from TFDS\n",
        "# If this is a validation set, the second parameter\n",
        "# will be true, so we set the split name to test, otherwise\n",
        "# it will be 'train'. And for the non validation sets\n",
        "# we'll shuffle them up \n",
        "def get_dataset(map_fn, is_validation=False):\n",
        "  if is_validation:\n",
        "    split_name = \"test\"\n",
        "  else:\n",
        "    split_name = \"train\"\n",
        "\n",
        "  dataset = tfds.load('mnist', as_supervised=True, split=split_name)\n",
        "  dataset = dataset.map(map_fn)\n",
        "  if is_validation:\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    dataset = dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jszTpjHVuJXO"
      },
      "source": [
        "# Create the 3 datasets, training, validation, and validation for predictions\n",
        "# with the third one having a different mapping function\n",
        "train_dataset = get_dataset(map_image)\n",
        "validation_dataset = get_dataset(map_image, is_validation=True)\n",
        "predict_val_dataset = get_dataset(map_image_with_labels, is_validation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLApb2VuzKZ"
      },
      "source": [
        "# The sampling class is a custom keras layer\n",
        "# that we will use to provide the gaussian noise\n",
        "# input along with the mean and standard deviation\n",
        "# of the encoder's output\n",
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU5kZsj0u9jX"
      },
      "source": [
        "# This function defines the encoder's layers\n",
        "def encoder_layers(inputs, latent_dim):\n",
        "  x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, padding=\"same\", activation='relu', name=\"encode_conv1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"encode_conv2\")(x)\n",
        "  batch_2 = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Flatten(name=\"encode_flatten\")(batch_2)\n",
        "  x = tf.keras.layers.Dense(20, activation='relu', name=\"encode_dense\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  mu = tf.keras.layers.Dense(latent_dim, name='latent_mu')(x)\n",
        "  sigma = tf.keras.layers.Dense(latent_dim, name ='latent_sigma')(x)\n",
        "  print(batch_2.shape)\n",
        "  return mu, sigma, batch_2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoLLpfBUvhBm"
      },
      "source": [
        "# And this one will define the e\n",
        "def encoder_model(latent_dim, input_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  mu, sigma, conv_shape = encoder_layers(inputs, latent_dim=LATENT_DIM)\n",
        "  z = Sampling()((mu, sigma))\n",
        "  model = tf.keras.Model(inputs, outputs=[mu, sigma, z])\n",
        "  return model, conv_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H_HoaAYvWZn"
      },
      "source": [
        "# This defines the decoder layers\n",
        "def decoder_layers(inputs, conv_shape):\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = tf.keras.layers.Dense(units, activation = 'relu', name=\"decode_dense1\")(inputs)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name=\"decode_reshape\")(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d_2\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name=\"decode_conv2d3\")(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='sigmoid', name=\"decode_final\")(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGZ5kqA4vuEy"
      },
      "source": [
        "# And this the decoder model\n",
        "def decoder_model(latent_dim, conv_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "  outputs = decoder_layers(inputs, conv_shape)\n",
        "  model = tf.keras.Model(inputs, outputs)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14Gla4K6vcLN"
      },
      "source": [
        "# Define a kl reconstruction loss function\n",
        "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  return tf.reduce_mean(kl_loss) * -0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hkx7OCqvzlb"
      },
      "source": [
        "# Define the vae model\n",
        "# Note the use of model.add_loss to add the kl reconstruciton loss\n",
        "# which is a complex function that doesn't use y_true and y_pred\n",
        "# so it can't be used in model.compile. \n",
        "#\n",
        "def vae_model(encoder, decoder, input_shape):\n",
        "  inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "  mu = encoder(inputs)[0]\n",
        "  sigma = encoder(inputs)[1]\n",
        "  z = encoder(inputs)[2]\n",
        "  reconstructed = decoder(z)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n",
        "  loss = kl_reconstruction_loss(inputs, z, mu, sigma)\n",
        "  model.add_loss(loss)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piqZLzkHv3jw"
      },
      "source": [
        "# Function to return all the models\n",
        "def get_models(input_shape, latent_dim):\n",
        "  encoder, conv_shape = encoder_model(latent_dim=latent_dim, input_shape=input_shape)\n",
        "  decoder = decoder_model(latent_dim=latent_dim, conv_shape=conv_shape)\n",
        "  vae = vae_model(encoder, decoder, input_shape=input_shape)\n",
        "  return encoder, decoder, vae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOp-yWg2v7uP"
      },
      "source": [
        "# Get the encoder, decoder and 'master' model (called vae)\n",
        "encoder, decoder, vae = get_models(input_shape=(28,28,1,), latent_dim=LATENT_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMWqvQqvwEMK"
      },
      "source": [
        "# Define our loss functions and optimizers\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "mse_loss = tf.keras.losses.MeanSquaredError()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ1mstGDwKma"
      },
      "source": [
        "# We'll generate 16 images in a 4x4 grid to show\n",
        "# progress of image generation\n",
        "random_vector_for_generation = tf.random.normal(shape=[16, LATENT_DIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaG0h17cwUYM"
      },
      "source": [
        "# Helper function to plot our 16 images\n",
        "def generate_and_save_images(model, epoch, step, test_input):\n",
        "  predictions = model.predict(test_input)\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\n",
        "  fig.suptitle(\"epoch: {}, step: {}\".format(epoch, step))\n",
        "  plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8o4ZPU1wSFc"
      },
      "source": [
        "# Training loop. Display generated images each epoch\n",
        "\n",
        "epochs = 100\n",
        "generate_and_save_images(decoder, 0, 0, random_vector_for_generation)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, x_batch_train in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      reconstructed = vae(x_batch_train)\n",
        "      # Compute reconstruction loss\n",
        "      flattened_inputs = tf.reshape(x_batch_train, shape=[-1])\n",
        "      flattened_outputs = tf.reshape(reconstructed, shape=[-1])\n",
        "      loss = bce_loss(flattened_inputs, flattened_outputs) * 784\n",
        "      \n",
        "      loss += sum(vae.losses)  # Add KLD regularization loss\n",
        "\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    loss_metric(loss)\n",
        "\n",
        "    if step % 100 == 0:\n",
        "      display.clear_output(wait=False)    \n",
        "      generate_and_save_images(decoder, epoch, step, random_vector_for_generation)\n",
        "      print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}